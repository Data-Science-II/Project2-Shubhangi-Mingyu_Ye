{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "'''\n",
    "import tensorflow as tp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import backend as K\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import regularizers \n",
    "'''\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils.fixes import _parse_version\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.400e+01 6.000e+00 2.000e+02 8.100e+01 3.012e+03 1.760e+01]\n",
      " [9.000e+00 8.000e+00 3.040e+02 1.930e+02 4.732e+03 1.850e+01]\n",
      " [1.200e+01 8.000e+00 4.290e+02 1.980e+02 4.952e+03 1.150e+01]\n",
      " ...\n",
      " [1.300e+01 8.000e+00 3.070e+02 1.300e+02 4.098e+03 1.400e+01]\n",
      " [2.550e+01 4.000e+00 1.400e+02 8.900e+01 2.755e+03 1.580e+01]\n",
      " [1.400e+01 8.000e+00 3.500e+02 1.650e+02 4.209e+03 1.200e+01]]\n",
      "[0, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "AutoMPG = pd.read_csv(\"auto-mpg.csv\", header = 1)\n",
    "Concrete = pd.read_csv(\"concrete.csv\", header = 1)\n",
    "ForestFires = pd.read_csv(\"forestfires.csv\", header = 1)\n",
    "SkillCraft = pd.read_csv(\"SkillCraft1_Dataset.csv\", header = 1)\n",
    "BiasCorrect = pd.read_csv(\"Bias_correction_ucl.csv\", header = 1)\n",
    "\n",
    "# X_AutoMPG = AutoMPG.drop(columns = ['model-year'])\n",
    "# Y_AutoMPG = AutoMPG[['model-year']]\n",
    "\n",
    "# X_Concrete = Concrete.drop(columns = ['Compressive Strength (28-day)(Mpa)'])\n",
    "# Y_Concrete = Concrete[['Compressive Strength (28-day)(Mpa)']]\n",
    "\n",
    "# X_ForestFires = ForestFires.drop(columns = ['month','day','area'])\n",
    "# Y_ForestFires = ForestFires[['area']]\n",
    "\n",
    "# X_SkillCraft = SkillCraft.drop(columns = ['ComplexAbilitiesUsed'])\n",
    "# Y_SkillCraft = SkillCraft[['ComplexAbilitiesUsed']]\n",
    "\n",
    "# X_BiasCorrect = BiasCorrect.drop(columns = ['Next_Tmin'])\n",
    "# Y_BiasCorrect = BiasCorrect[['Next_Tmin']]\n",
    "\n",
    "\n",
    "\n",
    "# X = X_AutoMPG.fillna(X_AutoMPG.mean())\n",
    "# y = Y_AutoMPG.fillna(Y_AutoMPG.mean())\n",
    "    \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_AutoMPG, Y_AutoMPG, random_state=1)\n",
    "# y_train.values\n",
    "# X_train.to_numpy()\n",
    "# y_test.to_numpy()\n",
    "# X_test.to_numpy()\n",
    "# print(y_train)\n",
    "\n",
    "# dataset = AutoMPG.to_numpy()\n",
    "# Y = dataset[:, -1]\n",
    "# X = dataset[:, :-1]\n",
    "    \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)   \n",
    "    \n",
    "# print(X_train[:,[0,1,2,3,4,5]])\n",
    "# print([0,1]+[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Regression with Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranReg_Ridge_Test(X, y): \n",
    "    f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(6.5, 8))\n",
    "    X = X.fillna(X.mean())\n",
    "    y = y.fillna(y.mean())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    regr = RidgeCV()\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    ax0[0].scatter(y_pred, y_test, s=8)\n",
    "    ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "    ax0[0].set_ylabel('True target')\n",
    "    ax0[0].set_xlabel('Predicted target')\n",
    "    ax0[0].text(s='Ridge regression \\n without target transformation', x=-5e4,\n",
    "                y=8e5, fontsize=12, multialignment='center')\n",
    "    ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "        r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\n",
    "    ax0[0].set_xlim([0, 7e5])\n",
    "    ax0[0].set_ylim([0, 7e5])\n",
    "    ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    ax1[0].scatter(y_pred, (y_pred - y_test), s=8)\n",
    "    ax1[0].set_ylabel('Residual')\n",
    "    ax1[0].set_xlabel('Predicted target')\n",
    "    ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    regr_trans = TransformedTargetRegressor(regressor=RidgeCV(), \n",
    "                                            func=np.log, inverse_func=np.exp)\n",
    "    regr_trans.fit(X_train, y_train)\n",
    "    y_pred = regr_trans.predict(X_test)\n",
    "\n",
    "    ax0[1].scatter(y_pred, y_test, s=8)\n",
    "    ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "    ax0[1].set_ylabel('True target')\n",
    "    ax0[1].set_xlabel('Predicted target')\n",
    "    ax0[1].text(s='Ridge regression \\n with target transformation', x=-5e4,\n",
    "                y=8e5, fontsize=12, multialignment='center')\n",
    "    ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "        r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\n",
    "    ax0[1].set_xlim([0, 7e5])\n",
    "    ax0[1].set_ylim([0, 7e5])\n",
    "    ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    ax1[1].scatter(y_pred, (y_pred - y_test), s=8)\n",
    "    ax1[1].set_ylabel('Residual')\n",
    "    ax1[1].set_xlabel('Predicted target')\n",
    "    ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    f.suptitle(\"AutoMPG model year\", y=0.035)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Regression with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranReg_Lasso_Test(X, y): \n",
    "    f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(6.5, 8))\n",
    "    X = X.fillna(X.mean())\n",
    "    y = y.fillna(y.mean())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    y_train.to_numpy()\n",
    "    X_train.to_numpy()\n",
    "    y_test.to_numpy()\n",
    "    X_test.to_numpy()\n",
    "\n",
    "    regr = Lasso()\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    ax0[0].scatter(y_pred, y_test, s=8)\n",
    "    ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "    ax0[0].set_ylabel('True target')\n",
    "    ax0[0].set_xlabel('Predicted target')\n",
    "    ax0[0].text(s='Lasso regression \\n without target transformation', x=-5e4,\n",
    "                y=8e5, fontsize=12, multialignment='center')\n",
    "    ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "        r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\n",
    "    ax0[0].set_xlim([0, 7e5])\n",
    "    ax0[0].set_ylim([0, 7e5])\n",
    "    ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    ax1[0].scatter(y_pred.T, (y_pred.T - y_test.T), s=8)\n",
    "    ax1[0].set_ylabel('Residual')\n",
    "    ax1[0].set_xlabel('Predicted target')\n",
    "    ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    regr_trans = TransformedTargetRegressor(regressor=RidgeCV(),\n",
    "                                            transformer=QuantileTransformer(n_quantiles=10,\n",
    "                                                                            output_distribution='normal'))\n",
    "    regr_trans.fit(X_train, y_train)\n",
    "    y_pred = regr_trans.predict(X_test)\n",
    "\n",
    "    ax0[1].scatter(y_pred, y_test, s=8)\n",
    "    ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "    ax0[1].set_ylabel('True target')\n",
    "    ax0[1].set_xlabel('Predicted target')\n",
    "    ax0[1].text(s='Lasso regression \\n with target transformation', x=-5e4,\n",
    "                y=8e5, fontsize=12, multialignment='center')\n",
    "    ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "        r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\n",
    "    ax0[1].set_xlim([0, 7e5])\n",
    "    ax0[1].set_ylim([0, 7e5])\n",
    "    ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    ax1[1].scatter(y_pred.T, (y_pred.T - y_test.T), s=8)\n",
    "    ax1[1].set_ylabel('Residual')\n",
    "    ax1[1].set_xlabel('Predicted target')\n",
    "    ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "    f.suptitle(\"AutoMPG model year\", y=0.035)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Regression with forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1],\n",
    "    df.values[:,-1:],\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "'''    \n",
    "\n",
    "regr_trans = TransformedTargetRegressor(regressor=LinearRegression(),\n",
    "                                        func=np.log, inverse_func=np.exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data): \n",
    "    dataset = data.to_numpy()\n",
    "    Y = dataset[:, -1]\n",
    "    X = dataset[:, :-1]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)   \n",
    "    \n",
    "    m,n=X.shape\n",
    "    \n",
    "    X_cols = [] # buffer list that tells which column index is in X right now...\n",
    "    X_cols_cv=[]\n",
    "    X_set=np.empty((m,0))#for test and train with cv..this would need to be different..\n",
    "    #need to save the below values for all models calculated in for loop and only save the best sse's\n",
    "    \n",
    "    m_train,n_train=X_train.shape\n",
    "    m_test,n_test=X_test.shape\n",
    "    X_train_set=np.empty((m_train,0))\n",
    "    X_test_set=np.empty((m_test,0))\n",
    "    \n",
    "    r_square=[]\n",
    "    r_adj=[]\n",
    "    r_square_cv=[]\n",
    "    \n",
    "    while (len(X_cols)<n):\n",
    "        sse=[]\n",
    "        r_square_best=[]\n",
    "        r_adj_best=[]\n",
    "        r_square_cv_best=[]\n",
    "        for i in range(0, n) :\n",
    "            if i not in X_cols :\n",
    "                #for rsq and radjsq\n",
    "                mno,nno=X_train_set.shape\n",
    "                X_train_set_copy=X_train[:, X_cols+[i]]\n",
    "                regr_trans.fit(X_train_set_copy, Y_train)\n",
    "                y_pred = regr_trans.predict(X_test)\n",
    "            \n",
    "                X_test_set_copy=X_test[:,X_cols+[i]]\n",
    "                r2 = r2_score(Y_test, y_pred)\n",
    "                r2_adj = 1-(1-r2)*(m-1)/(m-mno-1)\n",
    "                r_square_best.append(r2)\n",
    "                r_adj_best.append(r2_adj)                \n",
    "                r_square_cv_best.append(cross_val_score(regr_trans, X_train_set_copy, Y_train, cv=1))\n",
    "                \n",
    "                sse.append(mean_squared_error(Y_Test, y_pred))\n",
    "                \n",
    "            else: \n",
    "                sse.append(math.inf)#to\n",
    "                r_square_best.append(float('-inf'))\n",
    "                r_adj_best.append(float('-inf'))                \n",
    "                r_square_cv_best.append(float('-inf'))\n",
    "                \n",
    "        #for rsq and radjsq\n",
    "        best_index=sse.index(min(sse))\n",
    "        X_cols.append(best_index)\n",
    "        r_square_cv.append(r_square_cv_best[best_index])\n",
    "        r_adj_cv.append(r_adj_cv_best[best_index])\n",
    "        r_square.append(r_square_best[best_index])\n",
    "        r_adj.append(r_adj_best[best_index])\n",
    "\n",
    "    return r_square,r_adj,r_square_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-c4a1fb0466d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforward_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAutoMPG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-4b746006321b>\u001b[0m in \u001b[0;36mforward_selection\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mX_train_set_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cols\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mregr_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_set_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregr_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mX_test_set_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_cols\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_target.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m    228\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             pred_trans = self.transformer_.inverse_transform(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[0;32m    220\u001b[0m                                dense_output=True) + self.intercept_\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 6)"
     ]
    }
   ],
   "source": [
    "forward_selection(AutoMPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data):\n",
    "    dataset = data.to_numpy()\n",
    "    Y = dataset[:, -1]\n",
    "    X = dataset[:, :-1]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)   \n",
    "    \n",
    "    m,n=X.shape\n",
    "    X_cols = [] # buffer list that tells which column index is in X right now...\n",
    "    for j in range(n):\n",
    "        X_cols += [j]\n",
    "    X_set = np.empty((m,0))#for test and train with cv..this would need to be different..\n",
    "    #need to save the below values for all models calculated in for loop and only save the best sse's\n",
    "    \n",
    "    m_train,n_train=X_train.shape\n",
    "    m_test,n_test=X_test.shape\n",
    "    X_train_set=np.empty((m_train,0))\n",
    "    X_test_set=np.empty((m_test,0))\n",
    "    \n",
    "    r_square=[]\n",
    "    r_adj=[]\n",
    "    r_square_cv=[]\n",
    "    \n",
    "    while (len(X_cols)<n):\n",
    "        sse=[]\n",
    "        r_square_best=[]\n",
    "        r_adj_best=[]\n",
    "        r_square_cv_best=[]\n",
    "        for i in range(n-1,0,-1) :\n",
    "            if i not in X_cols :\n",
    "                #for rsq and radjsq\n",
    "                mno,nno=X_train_set.shape\n",
    "                X_train_set_copy=X_train[:, X_cols-[i]]\n",
    "                regr_trans.fit(X_train_set_copy,Y_train)\n",
    "                y_pred = regr_trans.predict(X_test)\n",
    "            \n",
    "                X_test_set_copy=X_test[:, X_cols-[i]]\n",
    "                r2 = r2_score(Y_test, y_pred)\n",
    "                r2_adj = 1-(1-r2)*(m-1)/(m-mno-1)\n",
    "                r_square_best.append(r2)\n",
    "                r_adj_best.append(r2_adj)                \n",
    "                r_square_cv_best.append(cross_val_score(regr_trans, X_train_set_copy, Y_train, cv=1))\n",
    "                \n",
    "                sse.append(mean_squared_error(Y_Test, y_pred))\n",
    "                \n",
    "            else: \n",
    "                sse.append(math.inf)#to\n",
    "                r_square_best.append(float('-inf'))\n",
    "                r_adj_best.append(float('-inf'))                \n",
    "                r_square_cv_best.append(float('-inf'))\n",
    "                \n",
    "        #for rsq and radjsq\n",
    "        best_index=sse.index(min(sse))\n",
    "        X_cols.append(best_index)\n",
    "        r_square_cv.append(r_square_cv_best[best_index])\n",
    "        r_adj_cv.append(r_adj_cv_best[best_index])\n",
    "        r_square.append(r_square_best[best_index])\n",
    "        r_adj.append(r_adj_best[best_index])\n",
    "\n",
    "    return r_square,r_adj,r_square_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
